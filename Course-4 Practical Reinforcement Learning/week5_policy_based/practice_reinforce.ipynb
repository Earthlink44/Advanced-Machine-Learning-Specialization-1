{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of practice_reinforce.ipynb","provenance":[{"file_id":"https://github.com/yandexdataschool/Practical_RL/blob/coursera/week5_policy_based/practice_reinforce.ipynb","timestamp":1589208924543}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Au3yNuyXL6hH","colab_type":"text"},"source":["# REINFORCE in TensorFlow\n","\n","Just like we did before for q-learning, this time we'll design a neural network to learn `CartPole-v0` via policy gradient (REINFORCE)."]},{"cell_type":"code","metadata":{"id":"GhkVo6VwL6hL","colab_type":"code","outputId":"2c9196d6-3a2e-4268-d6ad-d8187933108a","executionInfo":{"status":"ok","timestamp":1589208554469,"user_tz":-330,"elapsed":22628,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["import sys, os\n","if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n","    %tensorflow_version 1.x\n","    \n","    if not os.path.exists('.setup_complete'):\n","        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring20/setup_colab.sh -O- | bash\n","\n","        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n","        !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week5_policy_based/submit.py\n","\n","        !touch .setup_complete\n","\n","# This code creates a virtual display to draw game images on.\n","# It will have no effect if your machine has a monitor.\n","if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n","    !bash ../xvfb start\n","    os.environ['DISPLAY'] = ':1'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Selecting previously unselected package xvfb.\n","(Reading database ... 144429 files and directories currently installed.)\n","Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n","Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n","Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Starting virtual X frame buffer: Xvfb.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o2HB39g7L6hS","colab_type":"text"},"source":["A caveat: we have received reports that the following cell may crash with `NameError: name 'base' is not defined`. The [suggested workaround](https://www.coursera.org/learn/practical-rl/discussions/all/threads/N2Pw652iEemRYQ6W2GuqHg/replies/te3HpQwOQ62tx6UMDoOt2Q/comments/o08gTqelT9KPIE6npX_S3A) is to install `gym==0.14.0` and `pyglet==1.3.2`."]},{"cell_type":"code","metadata":{"id":"rWx8XQ0aL6hT","colab_type":"code","outputId":"cb313d17-fea7-4392-fcf9-70f0d13cfb06","executionInfo":{"status":"ok","timestamp":1589208560504,"user_tz":-330,"elapsed":3045,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"source":["import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","env = gym.make(\"CartPole-v0\")\n","\n","# gym compatibility: unwrap TimeLimit\n","if hasattr(env, '_max_episode_steps'):\n","    env = env.env\n","\n","env.reset()\n","n_actions = env.action_space.n\n","state_dim = env.observation_space.shape\n","\n","plt.imshow(env.render(\"rgb_array\"))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f9733820898>"]},"metadata":{"tags":[]},"execution_count":2},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"sv0IZ4UeL6hX","colab_type":"text"},"source":["# Building the network for REINFORCE"]},{"cell_type":"markdown","metadata":{"id":"pdsG9pXPL6hY","colab_type":"text"},"source":["For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n","\n","For numerical stability, please __do not include the softmax layer into your network architecture__.\n","We'll use softmax or log-softmax where appropriate."]},{"cell_type":"code","metadata":{"id":"MYkoC_eML6hc","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","# create input variables. We only need <s,a,R> for REINFORCE\n","states = tf.placeholder('float32', (None,)+state_dim, name=\"states\")\n","actions = tf.placeholder('int32', name=\"action_ids\")\n","cumulative_rewards = tf.placeholder('float32', name=\"cumulative_returns\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9a_tJFJjL6hh","colab_type":"code","outputId":"796bca9e-6486-4df2-d70c-c2e5bfada1db","executionInfo":{"status":"ok","timestamp":1589208630760,"user_tz":-330,"elapsed":1376,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["# <define network graph using raw tf or any deep learning library>\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Dense(128, activation='relu', input_shape=state_dim))\n","model.add(tf.keras.layers.Dense(64, activation='relu'))\n","model.add(tf.keras.layers.Dense(n_actions, activation='linear'))\n","\n","logits = model(states) # <linear outputs(symbolic) of your network>\n","\n","policy = tf.nn.softmax(logits)\n","log_policy = tf.nn.log_softmax(logits)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_B9HVvvUL6hk","colab_type":"code","colab":{}},"source":["# utility function to pick action in one given state\n","def get_action_proba(s):\n","    return policy.eval({states: [s]})[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"awMfQO9JL6hm","colab_type":"text"},"source":["#### Loss function and updates\n","\n","We now need to define objective and update over policy gradient.\n","\n","Our objective function is\n","\n","$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n","\n","\n","Following the REINFORCE algorithm, we can define our objective as follows: \n","\n","$$ \\hat J \\approx { 1 \\over N } \\sum_{s_i,a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G(s_i,a_i) $$\n","\n","When you compute gradient of that function over network weights $ \\theta $, it will become exactly the policy gradient."]},{"cell_type":"code","metadata":{"id":"NT5X6IimL6hn","colab_type":"code","colab":{}},"source":["# select log-probabilities for chosen actions, log pi(a_i|s_i)\n","indices = tf.stack([tf.range(tf.shape(log_policy)[0]), actions], axis=-1)\n","log_policy_for_actions = tf.gather_nd(log_policy, indices)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFI7zHu2L6hw","colab_type":"code","colab":{}},"source":["# policy objective as in the last formula. please use mean, not sum.\n","# note: you need to use log_policy_for_actions to get log probabilities for actions taken.\n","\n","J = tf.reduce_mean(log_policy_for_actions*cumulative_rewards) # <YOUR CODE>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XcieFQyVL6hz","colab_type":"code","colab":{}},"source":["# regularize with entropy\n","entropy = -tf.reduce_sum(policy*log_policy, axis=1) # <compute entropy. Don't forget the sign!>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwRic1FeL6h2","colab_type":"code","colab":{}},"source":["# all network weights\n","all_weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) # <a list of all trainable weights in your network>\n","\n","# weight updates. maximizing J is same as minimizing -J. Adding negative entropy.\n","loss = -J - 0.1*entropy\n","\n","update = tf.train.AdamOptimizer().minimize(loss, var_list=all_weights)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nzbvmUVmL6h4","colab_type":"text"},"source":["### Computing cumulative rewards"]},{"cell_type":"code","metadata":{"id":"9U7dKrLNL6h5","colab_type":"code","colab":{}},"source":["def get_cumulative_rewards(rewards,  # rewards at each step\n","                           gamma=0.99  # discount for reward\n","                           ):\n","    \"\"\"\n","    take a list of immediate rewards r(s,a) for the whole session \n","    compute cumulative rewards R(s,a) (a.k.a. G(s,a) in Sutton '16)\n","    R_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n","\n","    The simple way to compute cumulative rewards is to iterate from last to first time tick\n","    and compute R_t = r_t + gamma*R_{t+1} recurrently\n","\n","    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n","    \"\"\"\n","\n","    #<YOUR CODE>\n","    cumulative_rewards = np.array(rewards).astype(np.float32)\n","    for i in range(len(rewards)-2, -1, -1):\n","        cumulative_rewards[i] += gamma*cumulative_rewards[i+1]\n","\n","    return cumulative_rewards # <YOUR CODE: array of cumulative rewards>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oj5OyZQFL6iB","colab_type":"code","outputId":"efd2be9d-d4da-4da2-d504-971b42ba54a7","executionInfo":{"status":"ok","timestamp":1589208730776,"user_tz":-330,"elapsed":1180,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["assert len(get_cumulative_rewards(range(100))) == 100\n","assert np.allclose(\n","    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n","    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n","assert np.allclose(\n","    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n","    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n","assert np.allclose(\n","    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n","    [0, 0, 1, 2, 3, 4, 0])\n","print(\"looks good!\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["looks good!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FHSvnP6AL6iE","colab_type":"code","colab":{}},"source":["def train_step(_states, _actions, _rewards):\n","    \"\"\"given full session, trains agent with policy gradient\"\"\"\n","    _cumulative_rewards = get_cumulative_rewards(_rewards)\n","    update.run({states: _states, actions: _actions,\n","                cumulative_rewards: _cumulative_rewards})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kY9FuXIuL6iH","colab_type":"text"},"source":["### Playing the game"]},{"cell_type":"code","metadata":{"id":"5ctLS2cqL6iH","colab_type":"code","colab":{}},"source":["def generate_session(env, t_max=1000):\n","    \"\"\"play env with REINFORCE agent and train at the session end\"\"\"\n","\n","    # arrays to record session\n","    states, actions, rewards = [], [], []\n","\n","    s = env.reset()\n","\n","    for t in range(t_max):\n","\n","        # action probabilities array aka pi(a|s)\n","        action_probas = get_action_proba(s)\n","\n","        a = np.random.choice(n_actions, p=action_probas) # <pick random action using action_probas>\n","\n","        new_s, r, done, info = env.step(a)\n","\n","        # record session history to train later\n","        states.append(s)\n","        actions.append(a)\n","        rewards.append(r)\n","\n","        s = new_s\n","        if done:\n","            break\n","\n","    train_step(states, actions, rewards)\n","\n","    # technical: return session rewards to print them later\n","    return sum(rewards)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XL-9RUHfL6iO","colab_type":"code","outputId":"7eb2af3d-00ac-434c-9f3b-cba58570f558","executionInfo":{"status":"ok","timestamp":1589208841437,"user_tz":-330,"elapsed":79972,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["s = tf.InteractiveSession()\n","s.run(tf.global_variables_initializer())\n","\n","for i in range(100):\n","\n","    rewards = [generate_session(env) for _ in range(100)]  # generate new sessions\n","\n","    print(\"mean reward:%.3f\" % (np.mean(rewards)))\n","\n","    if np.mean(rewards) > 300:\n","        print(\"You Win!\")  # but you can train even further\n","        break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mean reward:54.360\n","mean reward:197.800\n","mean reward:426.880\n","You Win!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GIcqf3S7L6iT","colab_type":"text"},"source":["### Results & video"]},{"cell_type":"code","metadata":{"id":"dEArYAP1L6iT","colab_type":"code","colab":{}},"source":["# Record sessions\n","\n","import gym.wrappers\n","\n","with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n","    sessions = [generate_session(env_monitor) for _ in range(100)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bd1HvKJJL6iW","colab_type":"code","outputId":"8cf970c9-ebea-409b-c718-3fdcca303046","executionInfo":{"status":"ok","timestamp":1589208875871,"user_tz":-330,"elapsed":24603,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"resources":{"http://localhost:8080/videos/openaigym.video.0.120.video000064.mp4":{"data":"CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K","ok":false,"headers":[["content-length","1449"],["content-type","text/html; charset=utf-8"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":501}},"source":["# Show video. This may not work in some setups. If it doesn't\n","# work for you, you can download the videos and view them locally.\n","\n","from pathlib import Path\n","from IPython.display import HTML\n","\n","video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n","\n","HTML(\"\"\"\n","<video width=\"640\" height=\"480\" controls>\n","  <source src=\"{}\" type=\"video/mp4\">\n","</video>\n","\"\"\".format(video_names[-1]))  # You can also try other indices"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","<video width=\"640\" height=\"480\" controls>\n","  <source src=\"videos/openaigym.video.0.120.video000064.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"IUJTyJyiL6iZ","colab_type":"code","outputId":"475c6974-87ea-4c85-9c0b-e5e1f6577b03","executionInfo":{"status":"ok","timestamp":1589208920259,"user_tz":-330,"elapsed":66511,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from submit import submit_cartpole\n","submit_cartpole(generate_session, \"shekhawatnishidh5@gmail.com\", \"qRkEKXkk0a00GupF\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Submitted to Coursera platform. See results on assignment page!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1QFL_BziL6ib","colab_type":"code","colab":{}},"source":["# That's all, thank you for your attention!\n","# Not having enough? There's an actor-critic waiting for you in the honor section.\n","# But make sure you've seen the videos first."],"execution_count":0,"outputs":[]}]}